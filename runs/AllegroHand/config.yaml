task:
  name: AllegroHand
  physics_engine: ${..physics_engine}
  env:
    numEnvs: ${resolve_default:8192,${...num_envs}}
    envSpacing: 0.75
    episodeLength: 600
    clipObservations: 5.0
    clipActions: 1.0
    useRelativeControl: false
    dofSpeedScale: 20.0
    actionsMovingAverage: 1.0
    controlFrequencyInv: 4
    startPositionNoise: 0.01
    startRotationNoise: 0.0
    resetPositionNoise: 0.01
    resetRotationNoise: 0.0
    resetDofPosRandomInterval: 0.2
    resetDofVelRandomInterval: 0.0
    distRewardScale: -10.0
    rotRewardScale: 1.0
    rotEps: 0.1
    actionPenaltyScale: -0.0002
    reachGoalBonus: 250
    fallDistance: 0.24
    fallPenalty: 0.0
    velObsScale: 0.2
    objectType: block
    observationType: full
    successTolerance: 0.1
    printNumSuccesses: false
    maxConsecutiveSuccesses: 0
  sim:
    dt: 0.0083
    add_ground_plane: true
    add_distant_light: true
    use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
    use_flatcache: true
    enable_scene_query_support: false
    disable_contact_processing: false
    enable_cameras: false
    default_material:
      static_friction: 1.0
      dynamic_friction: 1.0
      restitution: 0.0
    physx:
      use_gpu: ${eq:${....sim_device},"gpu"}
      worker_thread_count: ${....num_threads}
      solver_type: ${....solver_type}
      bounce_threshold_velocity: 0.2
      friction_offset_threshold: 0.04
      friction_correlation_distance: 0.025
      enable_sleeping: true
      enable_stabilization: true
      gpu_max_rigid_contact_count: 524288
      gpu_max_rigid_patch_count: 33554432
      gpu_found_lost_pairs_capacity: 8192
      gpu_found_lost_aggregate_pairs_capacity: 262144
      gpu_total_aggregate_pairs_capacity: 1048576
      gpu_max_soft_body_contacts: 1048576
      gpu_max_particle_contacts: 1048576
      gpu_heap_capacity: 33554432
      gpu_temp_buffer_capacity: 16777216
      gpu_max_num_partitions: 8
    allegro_hand:
      override_usd_defaults: false
      enable_self_collisions: true
      enable_gyroscopic_forces: false
      solver_position_iteration_count: 8
      solver_velocity_iteration_count: 0
      sleep_threshold: 0.005
      stabilization_threshold: 0.0005
      density: -1
      max_depenetration_velocity: 1000.0
    object:
      override_usd_defaults: false
      make_kinematic: false
      enable_self_collisions: false
      enable_gyroscopic_forces: true
      solver_position_iteration_count: 8
      solver_velocity_iteration_count: 0
      sleep_threshold: 0.005
      stabilization_threshold: 0.0025
      density: 400.0
      max_depenetration_velocity: 1000.0
    goal_object:
      override_usd_defaults: false
      make_kinematic: true
      enable_self_collisions: false
      enable_gyroscopic_forces: true
      solver_position_iteration_count: 8
      solver_velocity_iteration_count: 0
      sleep_threshold: 0.0
      stabilization_threshold: 0.0025
      density: -1
      max_depenetration_velocity: 1000.0
train:
  params:
    seed: ${...seed}
    algo:
      name: a2c_continuous
    model:
      name: continuous_a2c_logstd
    network:
      name: actor_critic
      separate: false
      space:
        continuous:
          mu_activation: None
          sigma_activation: None
          mu_init:
            name: default
          sigma_init:
            name: const_initializer
            val: 0
          fixed_sigma: true
      mlp:
        units:
        - 512
        - 256
        - 128
        activation: elu
        d2rl: false
        initializer:
          name: default
        regularizer:
          name: None
    load_checkpoint: ${if:${...checkpoint},True,False}
    load_path: ${...checkpoint}
    config:
      name: ${resolve_default:AllegroHand,${....experiment}}
      full_experiment_name: ${.name}
      device: ${....rl_device}
      device_name: ${....rl_device}
      env_name: rlgpu
      multi_gpu: ${....multi_gpu}
      ppo: true
      mixed_precision: false
      normalize_input: true
      normalize_value: true
      value_bootstrap: true
      num_actors: ${....task.env.numEnvs}
      reward_shaper:
        scale_value: 0.01
      normalize_advantage: true
      gamma: 0.99
      tau: 0.95
      learning_rate: 0.0005
      lr_schedule: adaptive
      schedule_type: standard
      kl_threshold: 0.02
      score_to_win: 100000
      max_epochs: ${resolve_default:10000,${....max_iterations}}
      save_best_after: 100
      save_frequency: 200
      print_stats: true
      grad_norm: 1.0
      entropy_coef: 0.0
      truncate_grads: true
      e_clip: 0.2
      horizon_length: 16
      minibatch_size: 1600
      mini_epochs: 5
      critic_coef: 4
      clip_value: true
      seq_len: 4
      bounds_loss_coef: 0.0001
      player:
        deterministic: true
        games_num: 100000
        print_stats: true
task_name: ${task.name}
experiment: ''
num_envs: 100
minibatch_size: ''
seed: 42
torch_deterministic: false
max_iterations: ''
physics_engine: physx
pipeline: gpu
sim_device: gpu
device_id: 0
rl_device: cuda:0
multi_gpu: false
num_threads: 4
solver_type: 1
test: false
checkpoint: ''
headless: false
enable_livestream: false
mt_timeout: 30
wandb_activate: false
wandb_group: ''
wandb_name: ''
wandb_entity: ineogi2
wandb_project: omniisaacgymenvs
