# Task name - used to pick the class to load
task_name: ${task.name}
# experiment name. defaults to name of training config
experiment: ''

# if set to positive integer, overrides the default number of environments
num_envs: 1
minibatch_size: ''

# seed - set to -1 to choose random seed
seed: 42
# set to True for deterministic performance
torch_deterministic: False

# set the maximum number of learning iterations to train for. overrides default per-environment setting
max_iterations: ''

## Device config
physics_engine: 'physx'
# whether to use cpu or gpu pipeline
pipeline: 'gpu'
# whether to use cpu or gpu physx
sim_device: 'gpu'
# used for gpu simulation only - device id for running sim and task if pipeline=gpu
device_id: 0
# device to run RL
rl_device: 'cuda:0'
# multi-GPU training
multi_gpu: False

## PhysX arguments
num_threads: 4 # Number of worker threads per scene used by PhysX - for CPU PhysX only.
solver_type: 1 # 0: pgs, 1: tgs

# RLGames Arguments
# test - if set, run policy in inference mode (requires setting checkpoint to load)
test: False
# used to set checkpoint path
checkpoint: ''


# disables rendering
render: False
headless: ''
# enables native livestream
enable_livestream: False
# timeout for MT script
mt_timeout: 30

# set default task and default training config based on task
defaults:
  - task: Humanoid
  - train: ${task}PPO
  - hydra/job_logging: disabled


#----------------------------------
#------------- for SAC -------------
algorithm: SAC
model_num: ${now:%m%d}

model:
  hidden_sizes: [256, 256]
  buffer_size: 1.0e+6
  alpha: 0.2

training:
  epochs: 3000
  max_steps: 1000
  learning_rate: 0.0001
  gamma: 0.99
  batch_size: 2048
  save_frequency: 1
  save_dir: /home/kwon/rl_ws/isaac/outputs/${task_name}/${algorithm}/${model_num}

# data plot
wandb: False
board: False

# Run/sweep directories
hydra:
  run:
    dir: ./outputs/${task_name}/${algorithm}/${model_num}
  sweep:
    dir: ./outputs/sweeper_${task_name}/${algorithm}/${model_num}